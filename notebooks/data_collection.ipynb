{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection for Stock Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "The goal of this notebook is to collect the stock price data from Yahoo Finance and save it in an organised CSV file. In this project we will start off by using Coca-Cola (Ticker: KO)\n",
    "This will include:\n",
    "1. Setting up and opening the webpage\n",
    "2. Scraping the stock data table\n",
    "3. Processing the data and save it to a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n",
    "\n",
    "First, we must import all the necessary libraries to run this notebook.\n",
    "\n",
    "We will be importing:\n",
    "\n",
    "- **pandas**: This library is used for data manipulation and analysis. It provides data structures like DataFrames that will help us organise and clean the data we scrape.\n",
    "  \n",
    "- **selenium**: Selenium is a powerful tool for controlling web browsers through programs. It allows us to automate web scraping by navigating to web pages and extracting data programmatically.\n",
    "\n",
    "- **webdriver-manager**: This library is used to automatically manage the browser drivers required by Selenium. It ensures that the correct version of ChromeDriver is used to interact with Google Chrome.\n",
    "\n",
    "- **time**: This standard Python library is used to introduce delays in the code. We will use it to pause the execution for a few seconds, allowing the web page to fully load before scraping the data.\n",
    "\n",
    "- **os**: This library is used to create the folder in which the csv file will be saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Web Scraping Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Set Up and Open the Webpage\n",
    "First, we need to set up the Safari WebDriver to control the browser. Then, we will navigate to the Yahoo Finance page with historical data for Coca-Cola.\n",
    "We also handle the TimeoutError that may occur if the page takes too long to load.\n",
    "Note: I will be doing using safari as my Chrome does not work on my laptop, but the code for Chrome should work in a similar manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Safar ChromeDriver\n",
    "driver = webdriver.Safari()\n",
    "\n",
    "#Set the page load timeout \n",
    "driver.set_page_load_timeout(10)\n",
    "\n",
    "# Define the URL for Coca-Cola's historical stock data\n",
    "url = 'https://finance.yahoo.com/quote/KO/history/'\n",
    "\n",
    "try: \n",
    "    driver.get(url) # Open the URL and wait for it to load\n",
    "    time.sleep(5) # Wait for the page to load\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the page: {e}\")\n",
    "    driver.quit() # Close the driver if there's an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scrape the Table Data\n",
    "Next, we will locate the table element on the webpage and extract the rows and columns of stock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll to the bottom of th page to load all data\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True:\n",
    "    #scroll down to the bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2) # Wait for new data to load\n",
    "    # Check if the page height has stopped increasing\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "        \n",
    "# Find the table element by XPath\n",
    "try:\n",
    "    table = driver.find_element(By.XPATH, '//table')\n",
    "except Exception as e:\n",
    "    print(f\"Error finding the table: {e}\")\n",
    "    driver.quit()\n",
    "    \n",
    "# Extract the rows from the table\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "# Parse the table data into a list of rows, each containing cell data\n",
    "data = []\n",
    "for row in rows:\n",
    "    cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "    cols = [ele.text for ele in cols]\n",
    "    data.append(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process the Data and Save the File\n",
    "After collecting the data, we will close the browser driver, convert the data to a pandas DataFrame, and save it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/KO_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Convert data to a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Date', 'Open', 'High', 'Low', 'Close*', 'Adj Close**', 'Volume'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "file_path = 'data/KO_data.csv'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "# Now save the DataFrame to the CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "We have now successfully scraped historical stock price data for Coca-Cola (KO) from Yahoo Finance and saved it into a CSV file for future use. In the next step of the project we will preprocess this data for stock price prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
