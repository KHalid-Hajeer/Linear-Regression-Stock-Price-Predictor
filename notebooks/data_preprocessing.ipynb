{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Stock Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "The goal of this notebook is to preprocess the stock price data to prepare it for analysis and modeling.\n",
    "This will include:\n",
    "1. Loading the data  \n",
    "2. Handling missing data\n",
    "3. Feature engineering and target creation\n",
    "4. Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Importing Necessary Libraries\n",
    "First, we need to import all the libraries required to run what we want to do.\n",
    "We will be importing:\n",
    "- **pandas**: A library for data manipulation and analysis. We will use it to load and clean the data, as well as to perform feature engineering\n",
    "- **scikit-learn**: This library is a fundamental machine learning library. It allows to standardise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data\n",
    "First we need to load the raw stock price data saved as a CSV file. This file should have already been created using data_collection.ipynb (KO_data.csv).\n",
    "\n",
    "We will be doing this by creating a function called \"load_data\". It will:\n",
    "- Read the CSV file into a Pandas DataFrame\n",
    "- Remove any completely empty rows\n",
    "- Reset the index to ensure proper ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the stock price data from a CSV file.\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded data as a Pandas DataFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset from the CSV file\n",
    "        data = pd.read_csv(file_path, thousands=',', skip_blank_lines=True)\n",
    "       \n",
    "        # Remove any empty rows\n",
    "        data = data.dropna(how='all')\n",
    "       \n",
    "        # Reset the index to ensure continuity\n",
    "        data = data.reset_index(drop=True)\n",
    "        \n",
    "        print(\"Data loaded successfully.\")\n",
    "        print(data)\n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Handle Missing Data\n",
    "Next we will need to clean the dataset by handling any missing data and remove any rows that only display dividends.\n",
    "\n",
    "Note: we will be using a rolling mean over a 7-day window to fill in any missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_data(df):\n",
    "    \"\"\"\n",
    "    Fill missing values using a rolling mena(7-day window) and remove \"Dividend\" rows.\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe containing stock prices.\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned dataframe\n",
    "    \"\"\"\n",
    "    # Remove rows where any column contains the string \"Dividend\"\n",
    "    df = df[~df.apply(\n",
    "        lambda row: row.astype(str).str.contains(\"Dividend\", case=False, na=False).any(), axis=1\n",
    "    )]\n",
    "    \n",
    "    # Fill missing values for all columns\n",
    "    for column in df.columns: \n",
    "        if column != 'Date': # Skip the 'Date' column\n",
    "            df.loc[:, column] = df[column].fillna(df[column].rolling(window=7, min_periods=1, center=True).mean())\n",
    "    \n",
    "    # Reset data types\n",
    "    df['Open'] = df['Open'].astype(float)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering and Target Creation\n",
    "After having the CSV file cleaned, we will now create new potential features which may be useful for the linear regression.\n",
    "We will be engineering the following features:\n",
    "\n",
    "### Moving Averages and Bollinger Bands\n",
    "- **5-day Simple Moving Average (SMA_5)**: Average closing price over the last 5 days.\n",
    "- **20-day Simple Moving Average (SMA_20)**: Average closing price over the last 20 days.\n",
    "- **20-day Exponential Moving Average (EMA_20)**: Weighted average over the last 20 days but with more emphasis on recent data.\n",
    "- **50-day Exponential Moving Average (EMA_50)**: Similar to EMA_20 but over 50 days.\n",
    "- **Bollinger Bands (BB_upper, BB_lower)**: Indicate overbought or oversold conditions.\n",
    "\n",
    "### Volume-Based Indicators\n",
    "- **On-Balance Volume (OBV)**: Tracks volume flow.\n",
    "- **Volume Weighted Average Price (VWAP)**: Average price adjusted for volume.\n",
    "\n",
    "### Momentum Indicators\n",
    "- **Relative Strength Index (RSI)**: Indicates whether the stock is overbought or oversold.\n",
    "- **MACD**: Moving Average Convergence Divergence (MACD) shows trend strength.\n",
    "- **Stochastic Oscillator (%K, %D)**: Indicates momentum based on the closing price relative to high/low range.\n",
    "\n",
    "\n",
    "### Volatility Indicators\n",
    "- **Historical Volatility**: Standard deviation of percentage price changes.\n",
    "- **Rolling Standard Deviation**: Tracks price dispersion.\n",
    "\n",
    "Finally, we define the **target variable (Price Movement)** as the difference between the closing and opening prices.\n",
    "\n",
    "Note 1: We have engineered a lot of features which if all were used in our model may lead to overfitting.\n",
    "\n",
    "Note 2: We have a lot of features we want to create, so to maintain a clear structure and some level of modularity we will be splitting the features into different categories and create each category as a function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Moving Averages(SMA, EMA)\n",
    "def add_moving_averages(df):\n",
    "    \"\"\"\n",
    "    Add moving averages and Bollinger Bands.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe containing stock prices.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with new moving average features.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['SMA_5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['EMA_20'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
    "    df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
    "    df['BB_upper'] = df['SMA_20'] + (2 * df['Close'].rolling(window=20).std())\n",
    "    df['BB_lower'] = df['SMA_20'] - (2 * df['Close'].rolling(window=20).std())\n",
    "    return df\n",
    "    \n",
    "# 2. Volume-Based Indicators\n",
    "def add_volume_indicators(df):\n",
    "    \"\"\"\n",
    "    Add volume-based indicators (OBV, VWAP).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe containing stock prices.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with new volume-based features.\n",
    "    \"\"\"\n",
    "    df['OBV'] = (df['Volume'] * ((df['Close'] - df['Close'].shift(1)) > 0).astype(int)).cumsum()\n",
    "    df['VWAP'] = (df['Volume'] * df['Close']).cumsum() / df['Volume'].cumsum()\n",
    "    return df\n",
    "\n",
    "# 3. Momentum Indicators\n",
    "def add_momentum_indicators(df):\n",
    "    \"\"\"\n",
    "    Add Momentum indicators (RSI, MACD, Stochastic Oscillator)\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe containing stock prices.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with new momentum features\n",
    "    \"\"\"\n",
    "    #RSI calculations\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()                            \n",
    "    rs = gain / (loss + 1e-10) # Included a miniscule value to the denominator to prevent dividing by 0.\n",
    "    df['delta'] = delta\n",
    "    df['rs'] = rs\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD calculations\n",
    "    ema_12 = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    ema_26 = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = ema_12 - ema_26\n",
    "    df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    \n",
    "    # Stochastic Oscillator Calculations\n",
    "    low_min = df['Low'].rolling(window=14).min()\n",
    "    high_max = df['High'].rolling(window=14).max()\n",
    "    df['%K'] = 100 * ((df['Close'] - low_min) / (high_max - low_min))\n",
    "    df['%D'] = df['%K'].rolling(window=3).mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 4. Volatility Indicators\n",
    "def add_volatility_indicators(df):\n",
    "    \"\"\"\n",
    "    Add volatility indicators (historical volatility, rolling std deviation).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe containing stock prices.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with new volatility features.\n",
    "    \"\"\"\n",
    "    df['historical_volatility'] = df['Close'].pct_change().rolling(window=30).std()\n",
    "    df['rolling_std'] = df['Close'].rolling(window=20).std()\n",
    "    return df\n",
    "\n",
    "# Apply all features\n",
    "def apply_all_features(df):\n",
    "    \"\"\"\n",
    "    Apply all feature engineering functions.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe containing stock prices.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with all new features.\n",
    "    \"\"\"\n",
    "    df = add_moving_averages(df)\n",
    "    df = add_volume_indicators(df)\n",
    "    df = add_momentum_indicators(df)\n",
    "    df = add_volatility_indicators(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create the target\n",
    "def target_creation(df):\n",
    "    \"\"\"\n",
    "    Create the target variable (price movement).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe containing stock prices.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with target variable.\n",
    "    \"\"\"\n",
    "    df['Price Movement'] = df['Close'].to_numpy() - df['Open'].to_numpy()\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scaling the data\n",
    "Finally, we need to scale the data to ensure all features have a similar range, aiding the performance and convergence speed of the linear regression model. We will be using the standardising way of scaling the data using the Z-formula \n",
    "(X - mean) / standard deviation.\n",
    "\n",
    "Note: we will be putting the newly scaled data into new columns as to allow us to graph the scaled and unscaled features in exploratory_data_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(df):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Drop non-numerical columns and target column\n",
    "    features = df.drop(['Date', 'Price Movement'], axis=1)\n",
    "    \n",
    "    # Apply scaling\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "    # Create a new DataFrame with the scaled features, adjusting their headers\n",
    "    scaled_df = pd.DataFrame(scaled_features, columns=[col + '_standardised' for col in features.columns])\n",
    "    \n",
    "    # Align indices to avoid misalignment\n",
    "    scaled_df.index = df.index\n",
    "    \n",
    "    # Concatenate the scaled features back to the original DataFrame\n",
    "    df = pd.concat([df, scaled_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "             Date   Open   High    Low  Close  Adj Close      Volume\n",
      "0    Dec 18, 2024  62.81  63.64  62.79  62.85      62.85  20920300.0\n",
      "1    Dec 17, 2024  62.45  63.55  62.32  63.40      63.40  21902400.0\n",
      "2    Dec 16, 2024  63.23  63.86  62.35  62.55      62.55  24559700.0\n",
      "3    Dec 13, 2024  63.57  63.84  63.11  63.12      63.12  13429000.0\n",
      "4    Dec 12, 2024  63.55  63.92  63.22  63.84      63.84  17542100.0\n",
      "..            ...    ...    ...    ...    ...        ...         ...\n",
      "251  Dec 26, 2023  58.06  58.71  58.06  58.56      56.82   6422500.0\n",
      "252  Dec 22, 2023  58.12  58.46  58.02  58.32      56.59   9028500.0\n",
      "253  Dec 21, 2023  57.85  58.07  57.47  57.99      56.27  11725100.0\n",
      "254  Dec 20, 2023  58.50  58.67  57.57  57.61      55.90  17701000.0\n",
      "255  Dec 19, 2023  59.00  59.20  58.64  58.83      57.09  14612200.0\n",
      "\n",
      "[256 rows x 7 columns]\n",
      "           Date   Open   High    Low  Close  Adj Close      Volume   SMA_5  \\\n",
      "0  Dec 18, 2024  62.81  63.64  62.79  62.85      62.85  20920300.0     NaN   \n",
      "1  Dec 17, 2024  62.45  63.55  62.32  63.40      63.40  21902400.0     NaN   \n",
      "2  Dec 16, 2024  63.23  63.86  62.35  62.55      62.55  24559700.0     NaN   \n",
      "3  Dec 13, 2024  63.57  63.84  63.11  63.12      63.12  13429000.0     NaN   \n",
      "4  Dec 12, 2024  63.55  63.92  63.22  63.84      63.84  17542100.0  63.152   \n",
      "\n",
      "   SMA_20     EMA_20  ...  VWAP_standardised  delta_standardised  \\\n",
      "0     NaN  62.850000  ...          -1.798832                 NaN   \n",
      "1     NaN  62.902381  ...          -1.594454            1.076973   \n",
      "2     NaN  62.868821  ...          -1.748389           -1.586843   \n",
      "3     NaN  62.892743  ...          -1.724173            1.115028   \n",
      "4     NaN  62.982958  ...          -1.609203            1.400437   \n",
      "\n",
      "   rs_standardised  RSI_standardised  MACD_standardised  \\\n",
      "0              NaN               NaN           0.124389   \n",
      "1              NaN               NaN           0.184418   \n",
      "2              NaN               NaN           0.137993   \n",
      "3              NaN               NaN           0.163677   \n",
      "4              NaN               NaN           0.261935   \n",
      "\n",
      "   MACD_signal_standardised  %K_standardised  %D_standardised  \\\n",
      "0                  0.122731              NaN              NaN   \n",
      "1                  0.135244              NaN              NaN   \n",
      "2                  0.135577              NaN              NaN   \n",
      "3                  0.141198              NaN              NaN   \n",
      "4                  0.166177              NaN              NaN   \n",
      "\n",
      "   historical_volatility_standardised  rolling_std_standardised  \n",
      "0                                 NaN                       NaN  \n",
      "1                                 NaN                       NaN  \n",
      "2                                 NaN                       NaN  \n",
      "3                                 NaN                       NaN  \n",
      "4                                 NaN                       NaN  \n",
      "\n",
      "[5 rows x 48 columns]\n",
      "Data saved to data/preprocessed_KO_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l9/zmdgypk569x7yf8ttvk8fsbw0000gp/T/ipykernel_29331/2016457706.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Open'] = df['Open'].astype(float)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = load_data('data/KO_data.csv')\n",
    "    df = handle_missing_data(df)\n",
    "    df = apply_all_features(df)\n",
    "    df = target_creation(df)\n",
    "    df = scale_data(df)\n",
    "    print(df.head()) # To view the processed DataFrame\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'data/preprocessed_KO_data.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook we cleaned the raw historical stock price data for Coca-Cola (KO) and added new features and the target variable. We also scaled the all the features by standardisation using a built-in Scikit-Learn library that uses the Z-score formula.\n",
    "\n",
    "In the next step of the project we will explore the data, analysing it to look at relationships and more.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
